{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome to the Proper Hands On Session Involving Decision Trees!  \n",
    "\n",
    "### Our Objective is to perform a Multi Class Classification problem where we have the below:  \n",
    "\n",
    "-  Attribute Information:\n",
    "\t1. Class Name: 3 (L, B, R)\n",
    "\t2. Left-Weight: 5 (1, 2, 3, 4, 5)\n",
    "\t3. Left-Distance: 5 (1, 2, 3, 4, 5)\n",
    "\t4. Right-Weight: 5 (1, 2, 3, 4, 5)\n",
    "\t5. Right-Distance: 5 (1, 2, 3, 4, 5)\n",
    "-  Nomenclature:\n",
    "    1. L: The Balance Scale is **Left**  \n",
    "    2. B: The scale is properly **balanced**  \n",
    "    3. R: The balance scale is tipped to **Right Side**  \n",
    "\n",
    "- Find more about dataset here: [Balance Scale UCI link](https://archive.ics.uci.edu/ml/machine-learning-databases/balance-scale/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required packages \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "from sklearn.metrics import classification_report \n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "balance_data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-'+'databases/balance-scale/balance-scale.data',sep= ',', header = None,\n",
    "                           names = ['class_name','left_weight','left_distance','right_weight','right_distance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Length:  625\n",
      "Dataset Shape:  (625, 5)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 625 entries, 0 to 624\n",
      "Data columns (total 5 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   class_name      625 non-null    object\n",
      " 1   left_weight     625 non-null    int64 \n",
      " 2   left_distance   625 non-null    int64 \n",
      " 3   right_weight    625 non-null    int64 \n",
      " 4   right_distance  625 non-null    int64 \n",
      "dtypes: int64(4), object(1)\n",
      "memory usage: 24.5+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Printing the dataswet shape \n",
    "print(\"Dataset Length: \", len(balance_data)) \n",
    "print(\"Dataset Shape: \", balance_data.shape) \n",
    "print(balance_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_name</th>\n",
       "      <th>left_weight</th>\n",
       "      <th>left_distance</th>\n",
       "      <th>right_weight</th>\n",
       "      <th>right_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  class_name  left_weight  left_distance  right_weight  right_distance\n",
       "0          B            1              1             1               1\n",
       "1          R            1              1             1               2\n",
       "2          R            1              1             1               3\n",
       "3          R            1              1             1               4\n",
       "4          R            1              1             1               5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing the dataset obseravtions \n",
    "balance_data.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L    288\n",
      "R    288\n",
      "B     49\n",
      "Name: class_name, dtype: int64\n",
      "% i Class L 46.08\n",
      "% i Class R 46.08\n",
      "% i Class B 7.84\n"
     ]
    }
   ],
   "source": [
    "# Exploring the Target Variable\n",
    "\n",
    "target_var = balance_data.iloc[:,0]\n",
    "print(target_var.value_counts())\n",
    "\n",
    "# Let's check the Class Name Distribution\n",
    "\n",
    "print('% i Class L',round(target_var.value_counts()[0]/len(target_var)*100,2))\n",
    "print('% i Class R',round(target_var.value_counts()[1]/len(target_var)*100,2))\n",
    "print('% i Class B',round(target_var.value_counts()[2]/len(target_var)*100,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  Number of Instances: 625 (49 balanced, 288 left, 288 right)\n",
    "\n",
    "-  Class Distribution: \n",
    "   1. **46.08%** are L\n",
    "   2. **46.08%** are R\n",
    "   3. **7.84%** are B "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Value Count</th>\n",
       "      <th>% of Missing</th>\n",
       "      <th>DTYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>class_name</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>left_weight</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>left_distance</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>right_weight</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>right_distance</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Missing Value Count  % of Missing   DTYPE\n",
       "class_name                        0           0.0  object\n",
       "left_weight                       0           0.0   int64\n",
       "left_distance                     0           0.0   int64\n",
       "right_weight                      0           0.0   int64\n",
       "right_distance                    0           0.0   int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for Missing values\n",
    "\n",
    "def check_missing_values_function(df):\n",
    "    missing_values = df.isnull().sum()\n",
    "    missing_values_percent =round(100*(df.isnull().sum()/len(df)),2)\n",
    "    dtype = df.dtypes\n",
    "    info_df = pd.DataFrame({'Missing Value Count':missing_values,'% of Missing':missing_values_percent,'DTYPE': dtype})\n",
    "    info_df.sort_values(by = '% of Missing',inplace=True,ascending=False)\n",
    "    return info_df\n",
    "\n",
    "check_missing_values_function(balance_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Number of Attributes: 4 (numeric) + class name = 5\n",
    "\n",
    "- Missing Attribute Values: \n",
    "\t**NONE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So basically we have 3 levels of Target Levels which we want to target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, comes MODELLING a Decision Tree for finding the LABEL!  \n",
    " - First, we will use GINI INDEX Methodology  \n",
    " - Second, using the ID3, ENTROPY Methodology!  \n",
    " - Our Evaluation Metric is **Accuracy/Confusion Matrix**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gini Index Decision Tree**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating the target variable \n",
    "predictor_variables = balance_data.values[:, 1:5] \n",
    "target_variables = balance_data.values[:, 0] \n",
    "\n",
    "# Splitting the dataset into train and test \n",
    "X_train, X_test, y_train, y_test = train_test_split(predictor_variables, target_variables, test_size = 0.3, random_state = 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=3, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=5, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=100, splitter='best')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modelling using the GINI INDEX Score methodology\n",
    "clf_gini = DecisionTreeClassifier(criterion = \"gini\",\n",
    "                                  random_state = 100,max_depth=3, \n",
    "                                  min_samples_leaf=5) \n",
    "\n",
    "# Performing training \n",
    "clf_gini.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted values:\n",
      "\n",
      "['R' 'L' 'R' 'R' 'R' 'L' 'R' 'L' 'L' 'L' 'R' 'L' 'L' 'L' 'R' 'L' 'R' 'L'\n",
      " 'L' 'R' 'L' 'R' 'L' 'L' 'R' 'L' 'L' 'L' 'R' 'L' 'L' 'L' 'R' 'L' 'L' 'L'\n",
      " 'L' 'R' 'L' 'L' 'R' 'L' 'R' 'L' 'R' 'R' 'L' 'L' 'R' 'L' 'R' 'R' 'L' 'R'\n",
      " 'R' 'L' 'R' 'R' 'L' 'L' 'R' 'R' 'L' 'L' 'L' 'L' 'L' 'R' 'R' 'L' 'L' 'R'\n",
      " 'R' 'L' 'R' 'L' 'R' 'R' 'R' 'L' 'R' 'L' 'L' 'L' 'L' 'R' 'R' 'L' 'R' 'L'\n",
      " 'R' 'R' 'L' 'L' 'L' 'R' 'R' 'L' 'L' 'L' 'R' 'L' 'R' 'R' 'R' 'R' 'R' 'R'\n",
      " 'R' 'L' 'R' 'L' 'R' 'R' 'L' 'R' 'R' 'R' 'R' 'R' 'L' 'R' 'L' 'L' 'L' 'L'\n",
      " 'L' 'L' 'L' 'R' 'R' 'R' 'R' 'L' 'R' 'R' 'R' 'L' 'L' 'R' 'L' 'R' 'L' 'R'\n",
      " 'L' 'L' 'R' 'L' 'L' 'R' 'L' 'R' 'L' 'R' 'R' 'R' 'L' 'R' 'R' 'R' 'R' 'R'\n",
      " 'L' 'L' 'R' 'R' 'R' 'R' 'L' 'R' 'R' 'R' 'L' 'R' 'L' 'L' 'L' 'L' 'R' 'R'\n",
      " 'L' 'R' 'R' 'L' 'L' 'R' 'R' 'R']\n"
     ]
    }
   ],
   "source": [
    "# Making predictions on the TEST SET\n",
    "y_pred = clf_gini.predict(X_test) \n",
    "print(\"Predicted values:\")\n",
    "print()\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      "[[ 0  6  7]\n",
      " [ 0 67 18]\n",
      " [ 0 19 71]]\n",
      "\n",
      "Accuracy :  73.40425531914893\n",
      "\n",
      "Report :                precision    recall  f1-score   support\n",
      "\n",
      "           B       0.00      0.00      0.00        13\n",
      "           L       0.73      0.79      0.76        85\n",
      "           R       0.74      0.79      0.76        90\n",
      "\n",
      "    accuracy                           0.73       188\n",
      "   macro avg       0.49      0.53      0.51       188\n",
      "weighted avg       0.68      0.73      0.71       188\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Since, this is a MultiClass Classification Problem, We need to see the CLASSIFICATION REPORT\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print()\n",
    "print (\"Accuracy : \",accuracy_score(y_test,y_pred)*100) \n",
    "print()\n",
    "print(\"Report : \", classification_report(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Entropy Decision Tree!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',\n",
       "                       max_depth=3, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=5, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=100, splitter='best')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision tree with entropy \n",
    "clf_entropy = DecisionTreeClassifier(criterion = \"entropy\", \n",
    "                                     random_state = 100,max_depth = 3, \n",
    "                                     min_samples_leaf = 5) \n",
    "\n",
    "# Performing training\n",
    "clf_entropy.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted values:\n",
      "\n",
      "['R' 'L' 'R' 'L' 'R' 'L' 'R' 'L' 'R' 'R' 'R' 'R' 'L' 'L' 'R' 'L' 'R' 'L'\n",
      " 'L' 'R' 'L' 'R' 'L' 'L' 'R' 'L' 'R' 'L' 'R' 'L' 'R' 'L' 'R' 'L' 'L' 'L'\n",
      " 'L' 'L' 'R' 'L' 'R' 'L' 'R' 'L' 'R' 'R' 'L' 'L' 'R' 'L' 'L' 'R' 'L' 'L'\n",
      " 'R' 'L' 'R' 'R' 'L' 'R' 'R' 'R' 'L' 'L' 'R' 'L' 'L' 'R' 'L' 'L' 'L' 'R'\n",
      " 'R' 'L' 'R' 'L' 'R' 'R' 'R' 'L' 'R' 'L' 'L' 'L' 'L' 'R' 'R' 'L' 'R' 'L'\n",
      " 'R' 'R' 'L' 'L' 'L' 'R' 'R' 'L' 'L' 'L' 'R' 'L' 'L' 'R' 'R' 'R' 'R' 'R'\n",
      " 'R' 'L' 'R' 'L' 'R' 'R' 'L' 'R' 'R' 'L' 'R' 'R' 'L' 'R' 'R' 'R' 'L' 'L'\n",
      " 'L' 'L' 'L' 'R' 'R' 'R' 'R' 'L' 'R' 'R' 'R' 'L' 'L' 'R' 'L' 'R' 'L' 'R'\n",
      " 'L' 'R' 'R' 'L' 'L' 'R' 'L' 'R' 'R' 'R' 'R' 'R' 'L' 'R' 'R' 'R' 'R' 'R'\n",
      " 'R' 'L' 'R' 'L' 'R' 'R' 'L' 'R' 'L' 'R' 'L' 'R' 'L' 'L' 'L' 'L' 'L' 'R'\n",
      " 'R' 'R' 'L' 'L' 'L' 'R' 'R' 'R']\n"
     ]
    }
   ],
   "source": [
    "# Making predcitions on the TEST SET\n",
    "y_pred = clf_entropy.predict(X_test) \n",
    "print(\"Predicted values:\")\n",
    "print()\n",
    "print(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      "[[ 0  6  7]\n",
      " [ 0 63 22]\n",
      " [ 0 20 70]]\n",
      "\n",
      "Accuracy :  70.74468085106383\n",
      "\n",
      "Report :                precision    recall  f1-score   support\n",
      "\n",
      "           B       0.00      0.00      0.00        13\n",
      "           L       0.71      0.74      0.72        85\n",
      "           R       0.71      0.78      0.74        90\n",
      "\n",
      "    accuracy                           0.71       188\n",
      "   macro avg       0.47      0.51      0.49       188\n",
      "weighted avg       0.66      0.71      0.68       188\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Since, this is a MultiClass Classification Problem, We need to see the CLASSIFICATION REPORT\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print()\n",
    "print (\"Accuracy : \",accuracy_score(y_test,y_pred)*100) \n",
    "print()\n",
    "print(\"Report : \", classification_report(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyper-parameter Tuning!  \n",
    "- Define a Dictionary of Parameters.  \n",
    "- Pass the dictioary as **parameter arguments**  \n",
    "- Run the Decision Tree using **Grid Search CV method**!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 168 candidates, totalling 840 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  68 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done 840 out of 840 | elapsed:    5.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=DecisionTreeClassifier(ccp_alpha=0.0,\n",
       "                                              class_weight='balanced',\n",
       "                                              criterion='entropy',\n",
       "                                              max_depth=None, max_features=None,\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              presort='deprecated',\n",
       "                                              random_state=None,\n",
       "                                              splitter='best'),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'max_depth': [2, 5, 8, 11, 14, 17, 20],\n",
       "                         'max_features': [1, 4],\n",
       "                         'min_samples_leaf': [5, 10, 15, 20],\n",
       "                         'min_samples_split': [10, 20, 30]},\n",
       "             pre_dispatch='2*n_jobs', refit=['f1_score'],\n",
       "             return_train_score=True, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'max_depth': [2,5,8,11,14,17,20],\n",
    "    'min_samples_leaf': [5,10,15,20],\n",
    "    'min_samples_split': [10,20,30],\n",
    "    'max_features': [1, 4]\n",
    "}\n",
    "\n",
    "dt_hyper = DecisionTreeClassifier(class_weight='balanced',criterion = \"entropy\")\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(estimator = dt_hyper, param_grid = param_grid,refit=['f1_score'] ,\n",
    "                          cv = 5, n_jobs=-1, return_train_score=True,verbose=1)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We can get accuracy of 0.72 using {'max_depth': 11, 'max_features': 4, 'min_samples_leaf': 5, 'min_samples_split': 10}\n"
     ]
    }
   ],
   "source": [
    "print('We can get accuracy of',round(grid_search.best_score_,2),'using',grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=11, max_features=4, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=5, min_samples_split=10,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=100, splitter='best')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modelling using the GINI INDEX Score methodology\n",
    "dt_final_model = DecisionTreeClassifier(criterion = \"gini\",random_state = 100,max_depth=11, min_samples_leaf=5,min_samples_split=10,\n",
    "                                       max_features = 4) \n",
    "\n",
    "# Performing training \n",
    "dt_final_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted values:\n",
      "\n",
      "['L' 'L' 'R' 'L' 'R' 'L' 'R' 'L' 'L' 'L' 'L' 'L' 'R' 'L' 'R' 'R' 'L' 'L'\n",
      " 'R' 'L' 'R' 'L' 'B' 'L' 'R' 'L' 'L' 'L' 'R' 'L' 'L' 'L' 'R' 'L' 'L' 'L'\n",
      " 'L' 'R' 'L' 'L' 'R' 'L' 'R' 'L' 'R' 'R' 'L' 'B' 'R' 'L' 'L' 'R' 'L' 'L'\n",
      " 'R' 'L' 'R' 'R' 'L' 'B' 'L' 'R' 'L' 'L' 'L' 'R' 'R' 'R' 'R' 'L' 'L' 'R'\n",
      " 'R' 'L' 'R' 'L' 'R' 'R' 'R' 'L' 'R' 'R' 'L' 'R' 'L' 'R' 'R' 'L' 'R' 'L'\n",
      " 'R' 'R' 'L' 'L' 'L' 'R' 'R' 'L' 'L' 'L' 'R' 'L' 'R' 'R' 'R' 'R' 'R' 'R'\n",
      " 'L' 'L' 'R' 'L' 'R' 'R' 'L' 'L' 'R' 'R' 'R' 'R' 'L' 'R' 'R' 'L' 'L' 'L'\n",
      " 'L' 'L' 'L' 'R' 'R' 'R' 'R' 'L' 'R' 'R' 'R' 'L' 'L' 'R' 'L' 'L' 'L' 'R'\n",
      " 'L' 'L' 'R' 'L' 'R' 'R' 'L' 'L' 'L' 'R' 'R' 'R' 'L' 'R' 'R' 'B' 'R' 'R'\n",
      " 'B' 'L' 'R' 'R' 'L' 'R' 'R' 'R' 'L' 'R' 'B' 'R' 'L' 'R' 'R' 'L' 'R' 'R'\n",
      " 'B' 'R' 'R' 'L' 'L' 'R' 'R' 'R']\n"
     ]
    }
   ],
   "source": [
    "# Making predcitions on the TEST SET\n",
    "y_pred = dt_final_model.predict(X_test) \n",
    "print(\"Predicted values:\")\n",
    "print()\n",
    "print(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      "[[ 0  3 10]\n",
      " [ 2 77  6]\n",
      " [ 5  8 77]]\n",
      "\n",
      "Accuracy :  81.91\n",
      "\n",
      "Report :                precision    recall  f1-score   support\n",
      "\n",
      "           B       0.00      0.00      0.00        13\n",
      "           L       0.88      0.91      0.89        85\n",
      "           R       0.83      0.86      0.84        90\n",
      "\n",
      "    accuracy                           0.82       188\n",
      "   macro avg       0.57      0.59      0.58       188\n",
      "weighted avg       0.79      0.82      0.81       188\n",
      "\n",
      "\n",
      "F1 Score:  81.91\n"
     ]
    }
   ],
   "source": [
    "# Since, this is a MultiClass Classification Problem, We need to see the CLASSIFICATION REPORT\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print()\n",
    "print (\"Accuracy : \",round(accuracy_score(y_test,y_pred)*100,2)) \n",
    "print()\n",
    "print(\"Report : \", classification_report(y_test, y_pred)) \n",
    "print()\n",
    "print('F1 Score: ',round(f1_score(y_test, y_pred, average='micro')*100,2))\n",
    "\n",
    "# 'micro':\n",
    "# Calculate metrics globally by counting the total true positives, false negatives and false positives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusive Results:  \n",
    "- You can see that there is a **3%** Accuracy difference when we use the **Entropy Method**, however, the F1 Score, which is the trade Off which we should be looking seems more desirable for each class!  \n",
    "- We tried a Grid Search then using the GINI Method, to find the best Hyperprarameters!  \n",
    "- Here, our Hyperparamter Tuning was more focussed on Getting a Better Macro F1 Score! -> **72%** overall\n",
    "\n",
    "# Happy learning!ðŸŒŸ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
